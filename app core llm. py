from fastapi import APIRouter, Depends
from models import AskRequest, AskResponse, SearchResult
from app.core.vector import search
from app.core.security import get_api_key
import litellm

router = APIRouter()

async def generate_answer(query: str, context: str) -> str:
    prompt = f"""You are a JAMB genius helping students score 350+.

Use ONLY these past questions:

{context}

Question: {query}

Answer in clear Nigerian English. Explain well."""
    try:
        resp = litellm.completion(
            model="groq/llama3-70b-8192",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
            max_tokens=1000
        )
        return resp.choices[0].message.content
    except:
        return "AI no gree connect now. Try again small."

@router.post("/ask")
async def ask(req: AskRequest, _: str = Depends(get_api_key)):
    hits = await search(req.query, req.top_k)
    sources = [
        SearchResult(
            id=h.id, question=h.payload["question"][:500],
            subject=h.payload["subject"], year=h.payload["year"], score=h.score
        ) for h in hits
    ]

    context = "\n\n".join([f"{i+1}. [{h.payload['subject']} {h.payload['year']}]\n{h.payload['question'][:800]}"
                          for i, h in enumerate(hits[:5])])

    answer = await generate_answer(req.query, context if hits else "No past questions found.")

    return AskResponse(answer=answer, sources=sources)
